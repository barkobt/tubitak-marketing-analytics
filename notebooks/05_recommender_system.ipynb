{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 05 — Prescriptive Recommender System\n",
    "\n",
    "**Amaç:** 04. notebook'ta eğitilen dürüst \"Conversion Predictor\" modelini kullanarak, her müşteri için **hangi Kampanya Kanalı + Platform** ikilisinin dönüşüm olasılığını en çok artıracağını öneren bir **Prescriptive (Reçeteleyici) Öneri Sistemi** kurmak.\n",
    "\n",
    "**Akış:** 1) Varlık yükleme (model, scaler, imputer, test verisi) → 2) Strateji simülasyonu (`recommend_action`) → 3) Performans Lift analizi → 4) Segment–kanal heatmap ve feature importance ilişkisi."
   ],
   "id": "3719569765719296"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Predictive vs Prescriptive Analitik\n",
    "\n",
    "- **Predictive (Tahmine dayalı):** \"Ne olacak?\" sorusuna cevap verir. Örneğin: Bu müşterinin mevcut kanal/platform ile dönüşüm yapma olasılığı nedir?\n",
    "- **Prescriptive (Reçeteleyici):** \"Ne yapmalıyız?\" sorusuna cevap verir. Örneğin: Bu müşteriyi dönüştürmek için hangi kanal+platform kombinasyonunu kullanmalıyız?\n",
    "\n",
    "Bu notebook'ta, aynı tahmin modelini **simülasyon** ile kullanıyoruz: Tüm olası aksiyonları (kanal+platform çiftleri) deneyip en yüksek dönüşüm olasılığını veren aksiyonu **öneri** olarak sunuyoruz. Yani model pasif bir tahminci olmaktan çıkıp **aktif bir strateji motoru**na dönüşüyor."
   ],
   "id": "10b935a7bd9e464d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Model Persistence: Neden .pkl Dosyaları?\n",
    "\n",
    "04. notebook'ta eğitilen model, scaler ve imputer **disk üzerinde** `.pkl` (pickle) dosyaları olarak kaydedildi. Böylece:\n",
    "\n",
    "1. **Yeniden eğitim gerekmez:** Aynı pipeline (özellik hazırlama → impute → scale → tahmin) başka bir ortamda (bu notebook, API, vb.) tekrarlanabilir.\n",
    "2. **Versiyonlama:** Hangi modelin kullanıldığı nettir (`models/final_model.pkl`).\n",
    "3. **Tutarlılık:** Scaler ve imputer, eğitim verisi üzerinde fit edildiği için test/öneri verisinde **aynı dönüşümler** uygulanmalıdır; bu dosyalar olmadan özellik uzayı uyumsuz kalır.\n",
    "\n",
    "Bu notebook, `models/final_model.pkl`, `models/scaler.pkl` ve `models/imputer.pkl` dosyalarını yükleyerek 04. notebook ile **aynı** modeli kullanır."
   ],
   "id": "32b20976659c89b0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Klasik User-Based Collaborative Filtering'dan Farkı\n",
    "\n",
    "- **User-Based CF:** \"Senin gibi kullanıcılar şunu beğendi\" der; benzer kullanıcıların geçmiş davranışına dayanır. Çıktı genelde **ürün/içerik önerisi** (rating/item).\n",
    "- **Bu sistem:** Müşteri **profil özelliklerine** (yaş, gelir, geçmiş alışveriş vb.) ve **alabileceğimiz aksiyona** (hangi kanal+platform) bakarak, **dönüşüm olasılığını maksimize eden aksiyonu** önerir. Yani **aksiyon odaklı (action-oriented)** bir prescriptive sistemdir; \"kime ne yapmalıyız?\" sorusuna yanıt verir."
   ],
   "id": "8dd2437b40b6028c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Asset Retrieval\n",
    "\n",
    "Aşağıda 04. notebook ile uyumlu olacak şekilde:\n",
    "- `models/final_model.pkl`, `scaler.pkl`, `imputer.pkl` yükleniyor.\n",
    "- `marketing_analytics_featured.csv` üzerinden veri alınıyor; ROI_v2 ve CPA_v2 eklenip **Scenario D** feature seti ile `prepare_X` uygulanıyor.\n",
    "- Aynı `random_state` ile train/test split yapılarak **test seti** elde ediliyor (lift analizi için)."
   ],
   "id": "7cc6205da5a80760"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-31T22:17:31.930497Z",
     "start_time": "2026-01-31T22:17:31.640041Z"
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import warnings\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# --- Model, scaler, imputer yükleme (04. notebook ile aynı yol) ---\n",
    "MODELS_DIR = \"../models\"\n",
    "path_model = os.path.join(MODELS_DIR, \"final_model.pkl\")\n",
    "path_scaler = os.path.join(MODELS_DIR, \"scaler.pkl\")\n",
    "path_imputer = os.path.join(MODELS_DIR, \"imputer.pkl\")\n",
    "\n",
    "assert os.path.exists(\n",
    "    path_model), f\"Model bulunamadı: {path_model}. Önce 04_model_comparison.ipynb çalıştırıp modeli kaydedin.\"\n",
    "model = joblib.load(path_model)\n",
    "scaler = joblib.load(path_scaler)\n",
    "imputer = joblib.load(path_imputer)\n",
    "print(\"Yüklendi: final_model, scaler, imputer\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yüklendi: final_model, scaler, imputer\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-31T22:17:50.480803Z",
     "start_time": "2026-01-31T22:17:50.352694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Yüklendi: final_model, scaler, imputer\")\n",
    "# --- Veri yükleme (04 ile aynı kaynak) ---\n",
    "path_data = \"../data/marketing_analytics_featured.csv\"\n",
    "df = pd.read_csv(path_data)\n",
    "y = df[\"Conversion\"]"
   ],
   "id": "293901a21c7acc14",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yüklendi: final_model, scaler, imputer\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-31T22:17:57.660948Z",
     "start_time": "2026-01-31T22:17:57.643528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 04. notebook'taki gibi ROI_v2 ve CPA_v2 ekle (Scenario E/D feature seti için)\n",
    "df[\"ROI_v2\"] = (df[\"Income\"] * df[\"ClickThroughRate\"]) / (df[\"AdSpend\"].replace(0, np.nan).fillna(1) + 1)\n",
    "df[\"CPA_v2\"] = df[\"AdSpend\"] / (df[\"WebsiteVisits\"].replace(0, np.nan).fillna(1) + 1)"
   ],
   "id": "da046f601e3e2348",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-31T22:18:02.991185Z",
     "start_time": "2026-01-31T22:18:02.979455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for c in [\"ROI_v2\", \"CPA_v2\"]:\n",
    "    df[c] = df[c].replace([np.inf, -np.inf], np.nan)\n",
    "    df[c] = df[c].clip(upper=df[c].quantile(0.995))"
   ],
   "id": "609303f43a985767",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-31T22:18:09.530216Z",
     "start_time": "2026-01-31T22:18:09.512888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Scenario D: 04 ile aynı drop listesi\n",
    "BASE_DROP = [\"CustomerID\", \"Conversion\"]\n",
    "SCENARIOS = {\n",
    "    \"D\": BASE_DROP + [\"ConversionRate\", \"CTR_to_Conversion\", \"ROI_Proxy\", \"CPA_Proxy\"],\n",
    "}\n"
   ],
   "id": "bd24150825e00951",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-31T22:18:15.879734Z",
     "start_time": "2026-01-31T22:18:15.863729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_X(data, drop_cols):\n",
    "    \"\"\"drop_cols içindeki sütunları çıkarır, kategorikleri one-hot encode eder (04 ile aynı).\"\"\"\n",
    "    to_drop = [c for c in drop_cols if c in data.columns]\n",
    "    X = data.drop(columns=to_drop, errors=\"ignore\")\n",
    "    X = pd.get_dummies(X, drop_first=True)\n",
    "    for c in X.select_dtypes(include=[\"bool\"]).columns:\n",
    "        X[c] = X[c].astype(int)\n",
    "    return X"
   ],
   "id": "4e57236652d383b3",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-31T22:18:23.268527Z",
     "start_time": "2026-01-31T22:18:23.209711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_all = prepare_X(df, SCENARIOS[\"D\"])\n",
    "feature_columns = X_all.columns.tolist()\n",
    "print(\"Feature sayısı:\", len(feature_columns))"
   ],
   "id": "d7c5e269b7729bda",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature sayısı: 55\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-31T22:18:55.365990Z",
     "start_time": "2026-01-31T22:18:55.283792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Train/Test split (04 ile aynı; test seti lift analizi için) ---\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "# Test setindeki orijinal satır indeksleri (df üzerinden test müşterilerine erişim için)\n",
    "train_idx, test_idx = train_test_split(\n",
    "    np.arange(len(df)), test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "df_test = df.iloc[test_idx].reset_index(drop=True)\n",
    "X_test_imputed = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "X_test_s = scaler.transform(X_test_imputed)\n",
    "print(\"Test seti boyutu:\", len(df_test))"
   ],
   "id": "c6fad78df73de3bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test seti boyutu: 9600\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Strategy Simulation Logic: `recommend_action(customer_data)`\n",
    "\n",
    "Fonksiyon:\n",
    "1. Verilen **müşteri profilini** (tek satır) alır; sabit özellikleri (Age, Income, vb.) korur.\n",
    "2. **Değişken özellikleri** (CampaignChannel, AdvertisingPlatform) tüm olası kombinasyonlarla **cross-join** yaparak bir \"simülasyon veri seti\" oluşturur.\n",
    "3. Bu simülasyonu 04 ile aynı pipeline üzerinden geçirir (prepare_X → imputer → scaler → model).\n",
    "4. Her kanal/platform ikilisi için **Conversion Probability** hesaplar; en yüksek olasılığı veren kombinasyonu **Recommended Action** olarak döner."
   ],
   "id": "f67c3f9d6039e176"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-31T22:21:13.990408Z",
     "start_time": "2026-01-31T22:21:13.945678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tüm kanal ve platform değerleri (df'den; simülasyon için)\n",
    "CHANNELS = df[\"CampaignChannel\"].dropna().unique().tolist()\n",
    "PLATFORMS = df[\"AdvertisingPlatform\"].dropna().unique().tolist()\n",
    "print(\"Kanal sayısı:\", len(CHANNELS), \"| Platform sayısı:\", len(PLATFORMS))"
   ],
   "id": "63ec6b96e10b07c3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kanal sayısı: 7 | Platform sayısı: 7\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-31T22:21:30.249101Z",
     "start_time": "2026-01-31T22:21:30.230953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def recommend_action(customer_data, model=model, scaler=scaler, imputer=imputer,\n",
    "                     feature_columns=feature_columns, channels=CHANNELS, platforms=PLATFORMS,\n",
    "                     prepare_X=prepare_X, drop_cols=None):\n",
    "    \"\"\"\n",
    "    Bir müşteri profilini alır; tüm (CampaignChannel, AdvertisingPlatform) kombinasyonları\n",
    "    için dönüşüm olasılığını hesaplar ve en yüksek olasılığı veren aksiyonu önerir.\n",
    "\n",
    "    customer_data: df'den tek satır (Series) veya dict. Sabit özellikler korunur;\n",
    "                   sadece CampaignChannel ve AdvertisingPlatform varyasyonları üretilir.\n",
    "    Returns: dict with recommended_channel, recommended_platform, max_prob, prob_frame (tüm kombinasyonlar).\n",
    "    \"\"\"\n",
    "    if drop_cols is None:\n",
    "        drop_cols = SCENARIOS[\"D\"]\n",
    "    # Tek satırlık DataFrame yap\n",
    "    if isinstance(customer_data, pd.Series):\n",
    "        row_df = customer_data.to_frame().T\n",
    "    else:\n",
    "        row_df = pd.DataFrame([customer_data])\n",
    "\n",
    "    # Simülasyon: her (kanal, platform) çifti için aynı müşteri profilini kopyala\n",
    "    rows = []\n",
    "    for ch in channels:\n",
    "        for pl in platforms:\n",
    "            r = row_df.copy()\n",
    "            r[\"CampaignChannel\"] = ch\n",
    "            r[\"AdvertisingPlatform\"] = pl\n",
    "            rows.append(r)\n",
    "    sim_df = pd.concat(rows, ignore_index=True)\n",
    "\n",
    "    # Özellik matrisi (04 ile aynı prepare_X)\n",
    "    X_sim = prepare_X(sim_df, drop_cols)\n",
    "    # Model eğitiminde kullanılan sütun sırası ve eksik sütunları 0 ile doldur\n",
    "    X_sim = X_sim.reindex(columns=feature_columns, fill_value=0)\n",
    "    X_sim_imp = pd.DataFrame(imputer.transform(X_sim), columns=feature_columns, index=X_sim.index)\n",
    "    X_sim_s = scaler.transform(X_sim_imp)\n",
    "    probs = model.predict_proba(X_sim_s)[:, 1]\n",
    "\n",
    "    # Her satır (ch, pl) çiftine karşılık geliyor; sıra: channels x platforms (önce platform değişir)\n",
    "    prob_frame = pd.DataFrame({\n",
    "        \"CampaignChannel\": [ch for ch in channels for _ in platforms],\n",
    "        \"AdvertisingPlatform\": [pl for _ in channels for pl in platforms],\n",
    "        \"Conversion_Probability\": probs,\n",
    "    })\n",
    "    best_idx = np.argmax(probs)\n",
    "    best_row = prob_frame.iloc[best_idx]\n",
    "    return {\n",
    "        \"recommended_channel\": best_row[\"CampaignChannel\"],\n",
    "        \"recommended_platform\": best_row[\"AdvertisingPlatform\"],\n",
    "        \"max_prob\": best_row[\"Conversion_Probability\"],\n",
    "        \"prob_frame\": prob_frame,\n",
    "    }"
   ],
   "id": "3c4472a22209d43b",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-31T22:21:39.109398Z",
     "start_time": "2026-01-31T22:21:39.066011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Örnek: Test setinden bir müşteri için öneri\n",
    "sample_customer = df_test.iloc[0]\n",
    "rec = recommend_action(sample_customer)\n",
    "print(\"Örnek müşteri için önerilen aksiyon:\", rec[\"recommended_channel\"], \"+\", rec[\"recommended_platform\"])\n",
    "print(\"Tahmini dönüşüm olasılığı:\", round(rec[\"max_prob\"], 4))\n",
    "rec[\"prob_frame\"].sort_values(\"Conversion_Probability\", ascending=False).head()"
   ],
   "id": "50e64d415bfccaf0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Örnek müşteri için önerilen aksiyon: Display + LinkedIn\n",
      "Tahmini dönüşüm olasılığı: 0.1082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   CampaignChannel AdvertisingPlatform  Conversion_Probability\n",
       "35         Display            LinkedIn                0.108249\n",
       "37         Display            Facebook                0.106752\n",
       "28           Email            LinkedIn                0.103431\n",
       "36         Display           Instagram                0.102654\n",
       "30           Email            Facebook                0.101993"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CampaignChannel</th>\n",
       "      <th>AdvertisingPlatform</th>\n",
       "      <th>Conversion_Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Display</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>0.108249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Display</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>0.106752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Email</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>0.103431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Display</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>0.102654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Email</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>0.101993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a4a5b9913326b4e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
